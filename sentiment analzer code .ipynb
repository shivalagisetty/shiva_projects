{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sentiment                                            reviews\n",
      "count      25000                                              25000\n",
      "unique         3                                              24801\n",
      "top            1  Loved today's show!!! It was a variety and not...\n",
      "freq       12500                                                  5\n",
      "       sentiment                                            reviews\n",
      "count      25000                                              25000\n",
      "unique         2                                              24904\n",
      "top            1  How has this piece of crap stayed on TV this l...\n",
      "freq       12500                                                  3\n",
      "0        sentiment\n",
      "1                1\n",
      "2                1\n",
      "3                1\n",
      "4                1\n",
      "           ...    \n",
      "24995            0\n",
      "24996            0\n",
      "24997            0\n",
      "24998            0\n",
      "24999            0\n",
      "Name: sentiment, Length: 25000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Python packages to import \n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plot \n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "#Getting CSV file and setting column values\n",
    "df=pd.read_csv(r'C:\\Users\\Shiva\\Downloads\\movie_review_data.csv',sep=\",\", names=['sentiment','reviews'])\n",
    "df.loc[:, ['sentiment', 'reviews']] = df[['reviews', 'sentiment']].to_numpy()\n",
    "#Splitting csv into testing and traing data\n",
    "traindf =df.iloc[0:25000]\n",
    "testdf = df.iloc[25000:50000]\n",
    "#Getting info on training and testing data\n",
    "print(traindf.describe())\n",
    "print(testdf.describe())\n",
    "print(traindf.sentiment)\n",
    "\n",
    "#Ignore user and Package Warning if any\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lem_tokens(tokens, lemmatizer):\n",
    "    lemmetized = []\n",
    "    for item in tokens:\n",
    "        lemmetized.append(lemmatizer.lemmatize(item))\n",
    "    return lemmetized\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = re.sub(r'\\b\\w{1,3}\\b', '',text)\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # stem\n",
    "    stems = lem_tokens(tokens, lemmatizer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset=set(stopwords.words('english'))\n",
    "'''\n",
    "we can create our model using our training data. In creating the model, \n",
    "I will use the TF-IDF as the vectorizer and the Stochastic Gradient Descend algorithm as the classifier.\n",
    "'''\n",
    "# fit_transform fits the model and learns the vocabulary.Also it transforms our corpus data into feature vectors. \n",
    "vectorizer=TfidfVectorizer(use_idf=True,ngram_range=(1,2), lowercase=True,tokenizer=tokenize,strip_accents='ascii',max_features=1000,stop_words=stopset,norm='l1')\n",
    "#Taking first 25000 Reviews and sentiment for  training \n",
    "train_sentiments =traindf.sentiment\n",
    "\n",
    "train_text = vectorizer.fit_transform(traindf.reviews)\n",
    "#maps a dictonary for given sparse matrix \n",
    "vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentiment=testdf.sentiment\n",
    "test_text=vectorizer.transform(testdf.reviews)\n",
    "\n",
    "\n",
    "#Implement Stochalistic Gradient Descent to minimize the loss and updating the model \n",
    "classifier = SGDClassifier(alpha=1e-05,max_iter=50,penalty='elasticnet')\n",
    "#Training our Data Model\n",
    "classifier = classifier.fit(train_text, train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     12500\n",
      "           1       0.85      0.86      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n",
      "[[10581  1919]\n",
      " [ 1806 10694]]\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(test_text)\n",
    "\n",
    "# Model Evaluvation of other 25000 reviews\n",
    "#Examining accuracy precision recall and f1 results\n",
    "acc = accuracy_score(test_sentiment, predictions, normalize=True)\n",
    "hit = precision_score(test_sentiment, predictions, average=None)\n",
    "capture = recall_score(test_sentiment, predictions, average=None)\n",
    "print('Model Accuracy:%.2f'%acc)\n",
    "print(classification_report(test_sentiment, predictions))\n",
    "print(confusion_matrix(test_sentiment, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
